<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talk to Robot Samuel</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
            align-items: center;
            min-height: 100vh;
            background-image: url('../../../../imagens/fundo.png');
            background-repeat: repeat;
            margin: 0;
            padding: 20px;
        }
        #robot-img {
            width: 200px;
        }
        #speak-button {
            background-color: green;
            color: white;
            font-size: 16px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        #speak-button.listening {
            background-color: orange;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        #back-button {
            margin-top: 10px;
            background-color: black;
            color: white;
            font-size: 16px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);
            cursor: pointer;
        }
        #back-button:hover {
            background-color: #333;
        }
        button {
            margin: 10px;
        }
    </style>
</head>
<body>
    <h1>Talk to Robot Samuel</h1>
    <img id="robot-img" src="../../imagens/robo1_static.png" alt="Robot">
    <p id="message" style="visibility: hidden;">Loading...</p>
    <button id="speak-button" style="display: none;">Press to Start</button>
    <button id="back-button">Back</button>

    <!-- Firebase SDK -->
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-database.js"></script>

    <script>
        const firebaseConfig = {
            apiKey: "AIzaSyDGgo2H_hDKXF88xN7XnLFNUj8ikMY7Xdc",
            authDomain: "hannahenglishcourse.firebaseapp.com",
            databaseURL: "https://hannahenglishcourse-default-rtdb.asia-southeast1.firebasedatabase.app",
            projectId: "hannahenglishcourse",
            storageBucket: "hannahenglishcourse.appspot.com",
            messagingSenderId: "449818788486",
            appId: "1:449818788486:web:8a49d3f68591e6fb3f0707"
        };
        firebase.initializeApp(firebaseConfig);

        // Elementos DOM
        const messageElement = document.getElementById("message");
        const robotImg = document.getElementById("robot-img");
        const speakButton = document.getElementById("speak-button");
        const backButton = document.getElementById("back-button");

        const ROBOT_GIF = "../../imagens/robo1.gif";
        const ROBOT_STATIC = "../../imagens/robo1_static.png";
        const ROBOT_ALTERNATE = "../../imagens/robo2.gif";

        let recognition;
        let isSpeaking = false;
        let staticTime = 0;
        let alternateTimeout;
        let userId = null;
        let chatHistory = [];

        // Botão de voltar
        backButton.addEventListener("click", () => window.history.back());

        // Alternar imagem após 20 segundos de inatividade
        function startStaticImageTimer() {
            setInterval(() => {
                if (!isSpeaking) {
                    staticTime++;
                    if (staticTime === 20) {
                        robotImg.src = ROBOT_ALTERNATE;
                        alternateTimeout = setTimeout(() => {
                            robotImg.src = ROBOT_STATIC;
                            staticTime = 0;
                        }, 15000);
                    }
                }
            }, 1000);
        }

        function resetStaticTimer() {
            staticTime = 0;
            clearTimeout(alternateTimeout);
            robotImg.src = ROBOT_STATIC;
        }

       let hasWarnedUserAboutLang = false; // Variável para evitar mensagens repetidas
let voicesLoaded = false; // Variável para controlar se as vozes foram carregadas

// Evento para carregar as vozes disponíveis
function loadVoices() {
    const synth = window.speechSynthesis;
    let attempts = 0; // Contador de tentativas
    const maxAttempts = 20; // Número máximo de tentativas
    const intervalTime = 250; // Intervalo entre as tentativas (em ms)

    function checkVoices() {
        const voices = synth.getVoices();
        if (voices.length > 0) {
            voicesLoaded = true;
            console.log("Vozes carregadas com sucesso:", voices);
        } else {
            attempts++;
            if (attempts >= maxAttempts) {
                console.error("Erro: Não foi possível carregar as vozes após várias tentativas.");
                return; // Interrompe as tentativas
            }
            setTimeout(checkVoices, intervalTime); // Tenta novamente após o intervalo
        }
    }

    // Tenta carregar vozes ao inicializar
    checkVoices();

    // Adiciona suporte ao evento onvoiceschanged, caso o navegador o dispare
    if (typeof synth.onvoiceschanged !== "undefined") {
        synth.onvoiceschanged = () => {
            voicesLoaded = true;
            console.log("Vozes carregadas (evento onvoiceschanged):", synth.getVoices());
        };
    }
}

function getAvailableVoice(lang) {
    const voices = window.speechSynthesis.getVoices();
    return voices.find(voice => voice.lang === lang) || voices[0]; // Retorna a voz desejada ou a primeira disponível
}

// Função para fala do robô
function speak(text, rate = 0.8, lang = "en-US") {
    const synth = window.speechSynthesis;

    // Obter lista de vozes
    const voices = synth.getVoices();
    if (voices.length === 0) {
        console.warn("Nenhuma voz carregada. Tentando novamente...");
        setTimeout(() => speak(text, rate, lang), 500); // Rechama a função
        return;
    }

    // Selecionar a voz correta
    const selectedVoice = voices.find(voice => voice.lang === lang) || voices[0];
    console.log(`Usando voz: ${selectedVoice.name} (${selectedVoice.lang})`);

    // Configurar a fala
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.voice = selectedVoice;
    utterance.lang = selectedVoice.lang;
    utterance.rate = rate;

    // Eventos da fala
    utterance.onstart = () => {
        console.log("Fala iniciada...");
        isSpeaking = true;
        robotImg.src = ROBOT_GIF; // Mostra o GIF ativo
    };

    utterance.onend = () => {
        console.log("Fala finalizada...");
        isSpeaking = false;
        robotImg.src = ROBOT_STATIC; // Retorna à imagem estática
    };

    // Iniciar a fala
    synth.speak(utterance);
}

// Configuração do reconhecimento de voz
function setupSpeechRecognition() {
    if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
        alert("Speech recognition is not supported in this browser.");
        speakButton.disabled = true;
        return;
    }

    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-US";

    recognition.onstart = () => {
        isSpeaking = true; // Marca que está reconhecendo
        resetStaticTimer(); // Reseta o timer de inatividade
        robotImg.src = ROBOT_GIF; // Troca para GIF ativo
        speakButton.classList.add("listening");
        speakButton.innerText = "Listening...";
        console.log("Recognition started...");
    };

    recognition.onend = () => {
        isSpeaking = false; // Finaliza o estado de reconhecimento
        robotImg.src = ROBOT_STATIC; // Retorna à imagem estática
        speakButton.classList.remove("listening");
        speakButton.innerText = "Press to Speak";
        console.log("Recognition ended.");
    };

    recognition.onresult = async (event) => {
        const userSpeech = event.results[0][0].transcript;
        console.log("User speech:", userSpeech);

        // Exibe o texto capturado
        messageElement.style.visibility = "visible";
        messageElement.innerText = `You said: "${userSpeech}"`;

        if (!userId) {
            alert("User ID is missing. Please log in again.");
            return;
        }

        try {
            const response = await fetch('/api/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ uid: userId, message: userSpeech, chatHistory }),
            });
            const data = await response.json();

            if (!data.response) {
                console.error("Erro: Resposta da IA ausente.");
                return;
            }

            chatHistory = data.chatHistory; // Atualiza o histórico completo
            messageElement.innerText = data.response;
            speak(data.response); // Fala a resposta gerada
        } catch (error) {
            console.error("Error communicating with the server:", error);
            messageElement.innerText = "Error communicating with the server.";
        }
    };
}

async function initializeConversation() {
    firebase.auth().onAuthStateChanged(async (user) => {
        if (user) {
            userId = user.uid;
            console.log("User authenticated. User ID:", userId);

            const urlParams = new URLSearchParams(window.location.search);
            const level = urlParams.get('level') || 'Level1';
            const unit = urlParams.get('unit') || 'Unit1';

            try {
                const response = await fetch(`/api/start?uid=${userId}&level=${level}&unit=${unit}`);
                if (!response.ok) throw new Error("Failed to initialize conversation.");

                const data = await response.json();
                console.log("Server Response:", data);

                chatHistory = data.chatHistory || [];
                messageElement.innerText = data.response;

                messageElement.style.visibility = "hidden"; // Mensagem inicial será exibida após o clique

                // Exibe o botão "Press to Start" após a resposta do servidor
                speakButton.style.display = "block";

                if (!speakButton.hasAttribute('data-initialized')) {
                    speakButton.setAttribute('data-initialized', 'true');

                    speakButton.addEventListener("click", () => {
                        if (speakButton.innerText === "Press to Start") {
                            messageElement.style.visibility = "visible";
                            speak(data.response); // Fala a mensagem inicial
                            speakButton.innerText = "Press to Speak";
                        } else {
                            recognition.start();
                        }
                    });
                }
            } catch (error) {
                console.error("Error initializing conversation:", error);
                messageElement.innerText = "An unexpected error occurred. Try again later.";
                speakButton.disabled = true;
                messageElement.style.visibility = "visible";
            }
        } else {
            console.warn("User is not logged in.");
            messageElement.innerText = "Please log in to start the conversation.";
            messageElement.style.visibility = "visible";
        }
    });
}

// Configuração inicial quando a página carrega
document.addEventListener("visibilitychange", () => {
    if (document.hidden) window.speechSynthesis.cancel(); // Cancela a fala se a aba for minimizada
});

window.onload = () => {
    setupSpeechRecognition(); // Configura o reconhecimento de voz
    initializeConversation(); // Inicializa a conversa
    startStaticImageTimer(); // Inicia o timer de inatividade para troca de imagem
};
    </script>
</body>
</html>                                                     