<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talk to Robot Samuel</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
            align-items: center;
            min-height: 100vh;
            background-image: url('../../../../imagens/fundo.png');
            background-repeat: repeat;
            margin: 0;
            padding: 20px;
        }
        #robot-img {
            width: 200px;
        }
        #speak-button {
            background-color: green;
            color: white;
            font-size: 16px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        #speak-button.listening {
            background-color: orange;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        #back-button {
            margin-top: 10px;
            background-color: black;
            color: white;
            font-size: 16px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);
            cursor: pointer;
        }
        #back-button:hover {
            background-color: #333;
        }
        button {
            margin: 10px;
        }
    </style>
</head>
<body>
    <h1>Talk to Robot Samuel</h1>
    <img id="robot-img" src="../../imagens/robo1_static.png" alt="Robot">
    <p id="message" style="visibility: hidden;">Loading...</p>
    <button id="speak-button">Press to Start</button>
    <button id="back-button">Back</button>

    <!-- Firebase SDK -->
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-database.js"></script>

    <script>
        const firebaseConfig = {
            apiKey: "AIzaSyDGgo2H_hDKXF88xN7XnLFNUj8ikMY7Xdc",
            authDomain: "hannahenglishcourse.firebaseapp.com",
            databaseURL: "https://hannahenglishcourse-default-rtdb.asia-southeast1.firebasedatabase.app",
            projectId: "hannahenglishcourse",
            storageBucket: "hannahenglishcourse.appspot.com",
            messagingSenderId: "449818788486",
            appId: "1:449818788486:web:8a49d3f68591e6fb3f0707"
        };
        firebase.initializeApp(firebaseConfig);

        // Elementos DOM
        const messageElement = document.getElementById("message");
        const robotImg = document.getElementById("robot-img");
        const speakButton = document.getElementById("speak-button");
        const backButton = document.getElementById("back-button");

        const ROBOT_GIF = "../../imagens/robo1.gif";
        const ROBOT_STATIC = "../../imagens/robo1_static.png";
        const ROBOT_ALTERNATE = "../../imagens/robo2.gif";

        let recognition;   
        let staticTime = 0;
        let alternateTimeout;
        let userId = null;
        let chatHistory = [];

const MAX_HISTORY = 20; // Limita o histórico a 20 mensagens

function trimChatHistory() {
    if (chatHistory.length > MAX_HISTORY) {
        chatHistory = chatHistory.slice(-MAX_HISTORY); // Mantém as últimas 20 mensagens
    }
}

 // Botão de voltar
        backButton.addEventListener("click", () => window.history.back());

        // Alternar imagem após 20 segundos de inatividade
        function startStaticImageTimer() {
            setInterval(() => {
                if (!isSpeaking) {
                    staticTime++;
                    if (staticTime === 20) {
                        robotImg.src = ROBOT_ALTERNATE;
                        alternateTimeout = setTimeout(() => {
                            robotImg.src = ROBOT_STATIC;
                            staticTime = 0;
                        }, 15000);
                    }
                }
            }, 1000);
        }

        function resetStaticTimer() {
            staticTime = 0;
            clearTimeout(alternateTimeout);
            robotImg.src = ROBOT_STATIC;
        }

        let hasWarnedUserAboutLang = false; // Variável para evitar mensagens repetidas
let voicesLoaded = false; // Variável para controlar se as vozes foram carregadas

function loadVoices() {
    const synth = window.speechSynthesis;
    let voicesLoaded = false;

    // Exibe mensagem inicial enquanto as vozes carregam
    speakButton.disabled = true;
    speakButton.innerText = "Loading Voices...";

    // Verifica continuamente as vozes até que estejam disponíveis
    const fallbackInterval = setInterval(() => {
        const voices = synth.getVoices();
        if (voices.length > 0) {
            voicesLoaded = true;
            clearInterval(fallbackInterval);
            console.log("✅ Vozes carregadas com sucesso:", voices);
            speakButton.disabled = false; // Habilita o botão
            speakButton.innerText = "Press to Start";
        }
    }, 500); // Verifica a cada 500ms

    // Timeout final para evitar loops infinitos
    setTimeout(() => {
        if (!voicesLoaded) {
            clearInterval(fallbackInterval);
            console.error("⚠️ As vozes não carregaram dentro do tempo esperado.");
            alert("Vozes não carregaram. Verifique se o dispositivo suporta síntese de voz.");
            speakButton.disabled = true;
            speakButton.innerText = "Retrying Voices...";
        }
    }, 10000); // Timeout de 10 segundos
}

function getAvailableVoice(lang) {
    const voices = window.speechSynthesis.getVoices();

    // Priorizar vozes que contêm "en-US" no iOS
    const iosVoices = voices.filter(voice => voice.lang.includes("en") && voice.name.includes("Siri"));
    if (iosVoices.length > 0) return iosVoices[0];

    // Fallback para a lógica existente
    return voices.find(voice => voice.lang === lang) || voices[0];
}

// Declare 'isSpeaking' globalmente (apenas uma vez)
let isSpeaking = false; // Controle de estado de fala

function speak(text, rate = 0.8, lang = "en-US") {
    if (isSpeaking) return; // Previne chamadas simultâneas
    isSpeaking = true;

    if (!voicesLoaded) {
        console.warn("Voices not loaded yet. Trying again.");
        window.speechSynthesis.onvoiceschanged = () => speak(text, rate, lang);
        isSpeaking = false; // Libera o estado de fala caso falhe
        return;
    }

    const synth = window.speechSynthesis;
    const availableVoice = getAvailableVoice(lang);

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = availableVoice.lang;
    utterance.voice = availableVoice;
    utterance.rate = rate;

    let fallbackTimer;

    utterance.onstart = () => {
        console.log(`Speaking with voice: ${availableVoice.name} (${availableVoice.lang})`);
        speakButton.disabled = true;
        speakButton.innerText = "Robot is speaking...";

        // Fallback para redefinir o botão após o tempo estimado de fala
          const estimatedDuration = text.length / 15 * 1000; // Estima 15 caracteres por segundo
        fallbackTimer = setTimeout(() => {
            speakButton.disabled = false;
            speakButton.innerText = "Press to Speak";
            isSpeaking = false; // Libera o estado de fala
        }, estimatedDuration);
    };

    utterance.onend = () => {
        clearTimeout(fallbackTimer); // Cancela o fallback se o evento onend for acionado
        speakButton.disabled = false;
        speakButton.innerText = "Press to Speak";
        isSpeaking = false; // Libera o estado de fala
    };

    synth.speak(utterance);
}

// Ajuste na função de reconhecimento de voz
function setupSpeechRecognition() {
    if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
        alert("Speech recognition is not supported in this browser.");
        speakButton.disabled = true;
        return;
    }

    let isListening = false; // Variável para controlar o estado de escuta

    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-US";

    recognition.onstart = () => {
        isListening = true; // Define que está escutando
        speakButton.classList.add("listening");
        speakButton.innerText = "Listening...";
        console.log("Recognition started.");
    };

    recognition.onend = () => {
        isListening = false; // Define que parou de escutar
        speakButton.classList.remove("listening");
        speakButton.innerText = "Press to Speak";
        console.log("Recognition ended.");
    };

    recognition.onresult = async (event) => {
        const userSpeech = event.results[0][0].transcript;
        console.log("User speech:", userSpeech);

        // Exibe o texto capturado da fala do usuário no elemento de mensagem
        messageElement.style.visibility = "visible";
        messageElement.innerText = `You said: "${userSpeech}"`;

        if (!userId) {
            alert("User ID is missing. Please log in again.");
            return;
        }

        try {
            recognition.stop(); // Garante que o reconhecimento pare antes de processar a resposta
            const response = await fetch('/api/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ uid: userId, message: userSpeech, chatHistory }),
            });
            const data = await response.json();

            if (!data.response) {
                console.error("Error: Response from AI is missing.");
                return;
            }

            // Atualiza o histórico e fala a resposta
            chatHistory.push({ role: "user", content: userSpeech });
            trimChatHistory();

            chatHistory.push({ role: "assistant", content: data.response });
            trimChatHistory();

            messageElement.innerText = data.response;
            speak(data.response); // Chama o sintetizador para falar a resposta
        } catch (error) {
            console.error("Error communicating with the server:", error);
            messageElement.innerText = "Error communicating with the server.";
        }
    };

    speakButton.addEventListener("click", () => {
        if (!voicesLoaded) {
            alert("Voices are still loading. Please wait.");
            return;
        }

        if (isSpeaking || isListening) {
            alert("The robot is currently busy. Please wait for it to finish.");
            console.log("Robot is already busy speaking or listening.");
            return; // Evita múltiplas ações simultâneas
        }

        if (speakButton.innerText === "Press to Speak") {
            recognition.start(); // Inicia o reconhecimento de voz
        }
    });
}

async function initializeConversation() {
    firebase.auth().onAuthStateChanged(async (user) => {
        if (user) {
            userId = user.uid;
            console.log("User authenticated. User ID:", userId);

            const urlParams = new URLSearchParams(window.location.search);
            const level = urlParams.get('level') || 'Level1';
            const unit = urlParams.get('unit') || 'Unit1';

            try {
                const response = await fetch(`/api/start?uid=${userId}&level=${level}&unit=${unit}`);
                if (!response.ok) throw new Error("Failed to initialize conversation.");

                const data = await response.json();
                console.log("Server Response:", data);

                chatHistory = data.chatHistory || [];
                messageElement.innerText = data.response;

                messageElement.style.visibility = "hidden"; // Mensagem inicial será exibida após o clique

                if (!speakButton.hasAttribute('data-initialized')) {
                    speakButton.setAttribute('data-initialized', 'true');

                    speakButton.addEventListener("click", () => {
                        if (!voicesLoaded) {
                            alert("Voices are still loading. Please wait.");
                            return; // Impede interação até que as vozes estejam carregadas
                        }

                        if (speakButton.innerText === "Press to Start") {
                            messageElement.style.visibility = "visible";
                            speak(data.response || "Hello! I'm here to help you."); // Mensagem inicial padrão
                            speakButton.innerText = "Press to Speak";
                        } else if (!isSpeaking && !isListening) {
                            recognition.start(); // Inicia o reconhecimento de voz
                        }
                    });
                }
            } catch (error) {
                console.error("Error initializing conversation:", error);
                messageElement.innerText = "An unexpected error occurred. Try again later.";
                speakButton.disabled = true;
                messageElement.style.visibility = "visible";
            }
        } else {
            console.warn("User is not logged in.");
            messageElement.innerText = "Please log in to start the conversation.";
            messageElement.style.visibility = "visible";
        }
    });
}

// Configuração inicial quando a página carrega
document.addEventListener("visibilitychange", () => {
    if (document.hidden) window.speechSynthesis.cancel(); // Cancela a fala se a aba for minimizada
});

window.onload = () => {
    // Verifica se o dispositivo é iOS e exibe o alerta
    if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
        alert("Please ensure your device is not in silent mode and the volume is turned up.");
    }

    setupSpeechRecognition(); // Configura o reconhecimento de voz
    initializeConversation(); // Inicializa a conversa
    startStaticImageTimer(); // Inicia o timer de inatividade para troca de imagem
};
    </script>
</body>
</html>
