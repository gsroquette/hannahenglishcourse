<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talk to Lex</title>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        #robot-img {
            width: 200px;
        }
        #speak-button {
            background-color: green;
            color: white;
            font-size: 16px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        #speak-button.listening {
            background-color: orange;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
    </style>
</head>
<body>
    <h1>Talk to the Robot</h1>
    <img id="robot-img" src="../../imagens/robo1_static.png" alt="Robot">
    <p id="message">Loading...</p>
    <button id="speak-button">Press to Speak</button>

    <script>
        const ROBOT_GIF = "../../imagens/robo1.gif";
        const ROBOT_STATIC = "../../imagens/robo1_static.png";
        const messageElement = document.getElementById("message");
        const robotImg = document.getElementById("robot-img");
        const speakButton = document.getElementById("speak-button");

        let recognition;

        // Inicializar conversa
        async function initializeConversation() {
            try {
                console.log("Fetching initial conversation...");
                const response = await fetch('/api/start');
                const data = await response.json();
                console.log("Received data:", data);

                messageElement.innerText = data.response;

                // Garantir que vozes estejam carregadas antes de falar
                const waitForVoices = new Promise((resolve) => {
                    const synth = window.speechSynthesis;
                    if (synth.getVoices().length > 0) {
                        resolve();
                    } else {
                        synth.onvoiceschanged = resolve;
                    }
                });

                await waitForVoices;
                console.log("Vozes carregadas, iniciando fala...");
                speak(data.response);
            } catch (error) {
                console.error("Error initializing the conversation:", error);
                messageElement.innerText = "Error initializing the conversation.";
            }
        }

        // Função para o robô falar
        function speak(text) {
            const synth = window.speechSynthesis;
            const voices = synth.getVoices();
            const selectedVoice = voices.find((voice) => voice.lang === "en-US") || null;

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = "en-US";
            utterance.voice = selectedVoice;

            utterance.onstart = () => {
                robotImg.src = ROBOT_GIF; // Ativa GIF
            };

            utterance.onend = () => {
                robotImg.src = ROBOT_STATIC; // Volta ao estático
            };

            synth.speak(utterance);
        }

        // Configurar reconhecimento de voz
        function setupSpeechRecognition() {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = "en-US";
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(() => {
                    console.log("Microphone permission granted.");
                })
                .catch((error) => {
                    alert("Microphone permission denied. Please enable it in your browser settings.");
                    console.error("Microphone access error:", error);
                });

            recognition.onstart = () => {
                speakButton.classList.add("listening");
                speakButton.innerText = "Listening...";
            };

            recognition.onend = () => {
                speakButton.classList.remove("listening");
                speakButton.innerText = "Press to Speak";
            };

            recognition.onresult = async (event) => {
                const userSpeech = event.results[0][0].transcript;
                messageElement.innerText = `You said: ${userSpeech}`;
                try {
                    const response = await fetch('/api/chat', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ message: userSpeech })
                    });
                    const data = await response.json();
                    messageElement.innerText = data.response;
                    speak(data.response);
                } catch (error) {
                    console.error("Error communicating with the server:", error);
                    messageElement.innerText = "Error communicating with the server.";
                }
            };
        }

        speakButton.addEventListener("click", () => {
            if (recognition) {
                recognition.start();
            }
        });

        // Inicializar aplicação
        window.onload = () => {
            setupSpeechRecognition();
            initializeConversation();
        };
    </script>
</body>
</html>
